%%%%%%%%%%%%%%%%%%%%% chapter2.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% Summary chapter.
%
%
%%%%%%%%%%%%%%%%%%%%%%%% Universidad de Alicante %%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Summary in English}
\label{c2} % Always give a unique label
% use \chaptermark{}
% to alter or adjust the chapter heading in the running head

This PhD Thesis is composed of a set of published and submitted
papers. Therefore, this chapter is devoted to a description of
initial hypotheses, research objectives, and the collection of works
that are part of this Thesis, thus justifying its coherence. It
should be underlined that this chapter summarizes the scientific
content of this PhD Thesis, including research results and final
conclusions. Finally, the previous chapter has been written in
Spanish, and then translated into English as follows.

\section{PhD Thesis as a Collection of Papers}

In order to write this PhD Thesis as a collection of papers in the
University of Alicante, a set of requirements must be followed.
These requirements were defined by \emph{``Pleno de la Comisión de
Doctorado de la Universidad de Alicante''} on the 2nd of March,
2005; those related to the content of the PhD Thesis are presented
as follows:

\begin{enumerate}

\item \emph{``The PhD Thesis must include a summary written in one of the two official
languages of this region. It should contain objectives, hypotheses
and works to justify the coherence of the research.''}

\item \emph{``This summary must include an abstract to present the results, a discussion of them and the final
conclusions. This summary must give an idea of the overall content
of the PhD Thesis.''}

\item \emph{``The works presented in this PhD Thesis must be
published or accepted for publication after the beginning of the
PhD. Papers under review  can be included in the appendices of the
PhD Thesis.''}

\end{enumerate}

In order to fulfil the aforementioned requirements, this PhD Thesis
is structured in three parts. Part~\ref{p1} consists of a summary in
Spanish (Chapter~\ref{c1}) and its corresponding summary in English
(Chapter~\ref{c2}). Part~\ref{p2} presents a collection of published
papers. Part~\ref{p3} is an appendix which contains the papers that
are currently under the review process. Finally, it is worth
mentioning that this PhD Thesis has been developed thanks to the
funding of the Spanish Ministry of Education and Science under the
FPU grant program. In order to apply for this kind of grants, a
project for a PhD Thesis must be presented. Each research
publication is consequently a fundamental part of the global work,
forming a coherent collection.


\subsection{Publications Included in this PhD Thesis}
\label{c2:chapter} Four of the published research papers have been
selected to be part of this PhD Thesis due to (i) their scientific
contribution and (ii) their relevance. They are described in this
section.

\subsubsection{Chapter~\ref{c3}}

\emph{J.-N. Maz{\'o}n, J. Trujillo. An MDA approach for the
development of data warehouses. Decision Support Systems,
45(1):41--58, 2008. [IF2007: 1.119].}

This work describes a standard and integrated model-driven framework
for designing each component of a data warehouse. Once this
framework has been defined, the focus is on the multidimensional
modeling of the data warehouse repository. This work specifically
defines a conceptual multidimensional model and how it is translated
to a relational-based logical representation by using a model-driven
approach. The advantages of using the model-driven development to
design data warehouses are also enumerated.



\subsubsection{Chapter~\ref{c4}}

\emph{J.-N. Maz{\'o}n, J. Pardillo, J. Trujillo. Applying
Transformations to Model Driven Data Warehouses. 8th International
Conference on Data Warehousing and Knowledge Discovery (DaWaK 2006),
Krakow (Poland), September 4-8, 2006. Lecture Notes in Computer
Science Vol. 4081, pp. 13--22. [Acceptance rate: 36.3\%].}

Since the previous work had defined how to obtain a relational-based
implementation of the multidimensional conceptual model, this paper
focused on obtaining a logical representation directly based on
multidimensional technology, thus showing the full potential of
applying formal transformations within a model-driven approach,
thereby allowing designers to automatically implement it in any
commercial platform.


\subsubsection{Chapter~\ref{c5}}

\emph{J.-N. Maz{\'o}n, J. Trujillo, J. Lechtenb{\"o}rger.
Reconciling requirement-driven data warehouses with data sources via
multidimensional normal forms. Data \& Knowledge Engineering,
63(3):725--751, 2007. [IF2007: 1.144].}

The previous two works began by defining multidimensional models at
the conceptual level. However, successful data warehouse design
needs to be based upon a requirement analysis phase if they are to
represent the information needs of decision makers in a suitable
manner. Moreover, since the data warehouse integrates the
information provided by data sources, it is also crucial to take
these sources into account throughout the development process to
obtain a consistent reconciliation of data sources and information
needs. To the best of our knowledge, this is the first paper to
define a requirement analysis approach for multidimensional modeling
of data warehouses and the corresponding reconciliation process.


\subsubsection{Chapter~\ref{c6}}

\emph{J.-N. Maz{\'o}n, J. Trujillo. A Model Driven Modernization
Approach for Automatically Deriving Multidimensional Models in Data
Warehouses. 26th International Conference on Conceptual Modeling (ER
2007), Auckland (New Zealand), November 5-9, 2007. Lecture Notes in
Computer Science Vol. 4801, pp.56--71. [Acceptance rate: 22.2\%].}

The development of a data warehouse requires an in-depth analysis of
data sources. In the previous paper, it is assumed that a
documentation of the data sources is available. However, this is not
always true, since in real scenarios data sources are, in reality,
legacy systems and their manual analysis may be extremely difficult.
To overcome these problems, this paper considers the development of
a data warehouse as a modernization scenario which addresses the
analysis of the available data sources, thus discovering
multidimensional structures with which to either derive a
data-driven conceptual multidimensional model or reconcile a
requirement-driven conceptual multidimensional model with data
sources.


\subsection{Submitted Papers Included in this PhD Thesis}
\label{c2:appendix}

Three works that are part of this PhD Thesis are under review
process: two of them in high-quality journals and another in the
most relevant international workshop concerning data warehousing.

\subsubsection{Appendix~\ref{a1}}

\emph{A survey on summarizability issues in multidimensional
modeling. This paper has been submitted to the Data \& Knowledge
Engineering journal [IF2007: 1.144].}

The development of a data warehouse system is based on a conceptual
multidimensional model, which provides a high level of abstraction
in the accurate and expressive description of real-world situations.
Once this model has been designed, the corresponding logical
representation must be obtained as the basis of the implementation
of the data warehouse according to one specific technology. This
process is the main content of the PhD Thesis, and is described in
Chapters~\ref{c3}-\ref{c6}. However, although a good conceptual
multidimensional model is designed beneath a data warehouse, there
is a semantic gap between this model and its logical representation.
This gap particularly complicates a suitable treatment of
summarizability issues, which may in turn lead to erroneous results
from data analysis tools. Research addressing this topic has
produced only partial solutions, and individual terminology used by
different parties hinders further progress. Consequently, based on a
unifying vocabulary, the survey presented in this paper sheds light
on (i) the weak and strong points of current approaches for modeling
complex multidimensional structures that reflect real-world
situations in a conceptual model and (ii) existing mechanisms to
avoid summarizability problems when conceptual multidimensional
models are being implemented.

\subsubsection{Appendix~\ref{a2}}

\emph{Normalizing hierarchies to enforce summarizability in
multidimensional modeling. This work has been submitted to the
Information Systems journal [IF2007: 1.681].}

As is shown in the survey presented in Appendix~\ref{a1}, it is
crucial not only to capture adequate dimension hierarchies in the
conceptual multidimensional model of the data warehouse, but also to
correctly transform these multidimensional structures in a
summarizability-compliant representation. A normalization process is
therefore defined in this paper to address this
summarizability-aware transformation of the dimension hierarchies in
rich conceptual models.


\subsubsection{Appendix~\ref{a3}}

\emph{Solving summarizability problems in fact-dimension
relationships for multidimensional models. This paper has been
submitted to the ACM Eleventh International Workshop on Data
Warehousing and OLAP (DOLAP 2008).}

The results of the survey (Appendix~\ref{a1}) showed that the
avoidance of summarizability problems should take into account not
only dimension hierarchies, but also the relationships between facts
and dimensions. This paper therefore presents an approach for (i)
identifying problematic situations in fact-dimension relationships,
(ii) defining these relationships in a conceptual multidimensional
model, and (iii) applying a normalization process with which to
transform this conceptual multidimensional model into a
summarizability-compliant model that avoids erroneous analysis of
data.

%El desarrollo de estos trabajos fue el resultado de una estancia de
%investigación llevada a cabo durante los meses de julio, agosto y
%septiembre de 2007 en el \emph{European Research Center for
%Information Systems} de la \emph{Westfälische Wilhelms-Universität}
%de Münster (Alemania), bajo la tutela del catedrático Dr. Gottfried
%Vossen y el profesor Dr. Jens Lechtenbörger.


\subsection{Other Publications}
During the development of this PhD Thesis, several papers have been
also published. Although these publications are not explicitly
included in this PhD Thesis, they are also part of the research, and
complete it.

\subsubsection{Publications in International Journals}

\begin{description}

\item[\textbf{J-N. Mazón}, J. Trujillo, M. Serrano, M. Piattini.] Improving the
Development of Data Warehouses by Enriching Dimension Hierarchies
with WordNet. \emph{Lecture Notes in Computer Science vol. 4623,
Selection of the best papers at ODBIS 2005/2006, pp. 85-101, 2007.
ISSN: 0302-9743.}

\item[\textbf{J-N. Mazón}, J. Trujillo, M. Serrano, M. Piattini.] Applying MDA
to the development of data warehouses. \emph{Computing Reviews,
CR132357, 0611-1162. December 2006. ISSN: 1530-6585.}

\item[E. Soler, V. Stefanov, \textbf{J.-N. Mazón}, J. Trujillo, E.
Fernández-Medina, M. Piattini.] Una aproximación basada en i* para
el análisis de requisitos de seguridad en Almacenes de Datos.
\emph{Revista IEEE América Latina 6(3), July 2008. ISSN: 1548-0992.}

\item[\textbf{J-N. Mazón}, J. Trujillo.] Ingeniería inversa dirigida por
modelos para el diseño de almacenes de datos. \emph{Revista IEEE
América Latina 6(4), August 2008. ISSN: 1548-0992.}

\end{description}

\subsubsection{Book Chapters}

\begin{description}
\item[\textbf{J-N. Mazón}, J. Trujillo.] Data Warehousing Meets MDA: A Case
Study for Multidimensional Modeling. \emph{New Trends in Data
Warehousing and Data Analysis. Kozielski, Stanislaw; Wrembel, Robert
(Eds.) Annals of Information Systems , Vol. 3, pp. 51--70, 2009.
ISBN: 978-0-387-87430-2.}
\end{description}

%Database Encyclopedia


\subsubsection{Publications in International Conferences}

\begin{description}

\item[L. Muñoz, \textbf{J-N. Mazón}, J. Pardillo, J. Trujillo.] Modelling ETL
Processes of Data Warehouses with UML Activity Diagrams. \emph{1st
International Workshop On Ambient Data Integration (ADI '08),
November 11, 2008, Monterrey (Mexico). Lecture Notes in Computer
Science, in press. ISSN: 0302-9743.}

\item[E. Soler, V. Stefanov, \textbf{J-N. Mazón}, J. Trujillo, E.
Fernández-Medina, M. Piattini.] Towards Comprehensive Requirement
Analysis for Data Warehouses: Considering Security Requirements.
\emph{3rd International Conference on Availability, Reliability and
Security (ARES 2008), March 4-7, 2008, Barcelona (Spain). IEEE
Computer Society 2008, pp. 104--111.}

\item[J. Pardillo, \textbf{J-N. Mazón}, J. Trujillo.] Towards the Automatic
Generation of Analytical End-User Tools Metadata for Data
Warehouses. \emph{25th British National Conference on Databases
(BNCOD 25), Cardiff (UK), July 7-10, 2008. Lecture Notes in Computer
Science 5071, pp. 203--206. ISSN: 0302-9743.}

\item[J. Pardillo, \textbf{J-N. Mazón}, J. Trujillo.] Model-Driven Metadata for
OLAP Cubes from the Conceptual Modelling of Data Warehouses.
\emph{10th International Conference on Data Warehousing and
Knowledge Discovery (DaWaK 2008), Turin (Italy), September 2-5,
2008. Lecture Notes in Computer Science 5182, pp. 13--22. ISSN:
0302-9743.}

\item[\textbf{J-N. Mazón}, J. Pardillo, E. Soler, O. Glorio, J. Trujillo.]
Applying the i* Framework to the Development of Data Warehouses.
\emph{3rd International i* Workshop (iStar 2008), Recife (Brazil),
February 11-12, 2008. CEUR Workshop Proceedings 322, pp. 79--82.
ISSN 1613-0073.}

\item[E. Soler, V. Stefanov, \textbf{J-N. Mazón}, J. Trujillo, E.
Fernández-Medina, M. Piattini.] Modelado de requisitos de seguridad
para almacenes de datos. \emph{XI Workshop Iberoamericano de
Ingeniería de Requisitos y Ambientes de Software (IDEAS 2008),
Recife (Brazil), February 11-15, 2008, pp. 281--294. ISBN:
978-8570841346.}

\item[O. Glorio, J. Pardillo, \textbf{J-N. Mazón}, J. Trujillo.] DaWaRA: an
Eclipse Plugin for Using i* on Data Warehouse Requirement Analysis.
\emph{16th IEEE International Requirements Engineering Conference
(RE'08), Barcelona (Spain), September 8-12, 2008. ISSN: 1090-705X.}

\item[\textbf{J-N. Mazón}, J. Trujillo, and J. Lechtenbörger.] A Set of QVT
Relations to Assure the Correctness of Data Warehouses by Using
Multidimensional Normal Forms. \emph{25th International Conference
on Conceptual Modeling (ER 2006), LNCS 4215, pp.385-398, Tucson, AZ
(USA), November 6-9, 2006. ISSN: 0302-9743.}

\item[\textbf{J-N. Mazón}, J. Pardillo and J. Trujillo.] A Model-Driven
Goal-Oriented Requirement Engineering Approach for Data Warehouses.
\emph{International Workshop on Requirements, Intentions and Goals
in Conceptual Modeling (RIGiM07), LNCS 4802, pp.255-264, Auckland
(New Zealand), November 5-9, 2007. ISSN: 0302-9743.}

\item[\textbf{J-N. Mazón}, J. Trujillo.] Enriching Data Warehouse Dimension
Hierarchies by Using Semantic Relations. \emph{23rd British National
Conference on Databases (BNCOD 2006). LNCS 4042, pp.278-281, Belfast
(UK), July 18-20, 2006. ISSN: 0302-9743.}

\item[\textbf{J-N. Mazón}, J. Trujillo.] Query/View/Transformation Language
for Multidimensional Modeling of Data Warehouses. \emph{European
Workshop on Milestones, Models and Mappings for Model-Driven
Architecture (3M4MDA), CTIT Workshop Proceedings Series, WP06-02,
pp. 65-80. Bilbao, Spain, July 11, 2006. ISSN: 1574-0846.}

\item[M. Serrano, R. Romero, \textbf{J-N. Mazón}, J. Trujillo, M. Piattini.] A
Proposal for a Conceptual Data Warehouse Quality Model. \emph{19th
International Conference on Software Engineering \& Knowledge
Engineering (SEKE'2007), pp. 477-482, Boston, Massachusetts, USA,
July 9-11, 2007. ISBN 1-891706-20-9.}

\item[\textbf{J-N. Mazón}, J. Trujillo, M. Serrano, M. Piattini.] Applying MDA
to the development of data warehouses. \emph{ACM 8th International
Workshop on Data Warehousing and OLAP (DOLAP 2005), pp. 57-66,
Bremen, Germany, November 4-5, 2005, ISBN 1-59593-162-7.}

\item[\textbf{J-N. Mazón}, J. Trujillo, M. Serrano, M. Piattini.] Using WordNet
Ontology to automatically enrich dimension hierarchies in a data
warehouse. \emph{VLDB International Workshop on Ontologies-based
techniques for DataBases and Information Systems (ODBIS 2005), pp.
24-30. September 2-3, 2005, Trondheim, Norway.}

\item[\textbf{J-N. Mazón}, J. Trujillo, M. Serrano, M. Piattini.] Designing Data
Warehouses: From Business Requirement Analysis to Multidimesional
Modeling. \emph{International Workshop on Requirements Engineering
for Business Need and IT Alignment (REBNITA 2005), pp. 22-53. August
29-30, 2005, Paris, France. ISBN 73-3422-764.}

\end{description}

\subsubsection{Publications in National Conferences}

\begin{description}

\item[J. Pardillo, \textbf{J-N. Mazón}, J. Trujillo.] Ingeniería dirigida por
modelos conceptuales en el diseño de metadatos OLAP. \emph{XIII
Jornadas de Ingeniería del Software y Bases de Datos (JISBD 2008),
pp. 123-134, October 7-10, Gijón, Spain. ISBN: 978-84-612-5820-8.}

\item[L. Muñoz, \textbf{J-N. Mazón}, J. Pardillo, J. Trujillo.] Una aproximación
basada en Diagramas de Actividades de UML para el Modelado
Conceptual de Procesos ETL en Almacenes de Datos. \emph{XIII
Jornadas de Ingeniería del Software y Bases de Datos (JISBD 2008),
pp. 217-228, October 7-10, Gijón, Spain. ISBN: 978-84-612-5820-8.}

\item[C. Cachero, J. Pardillo, \textbf{J-N. Mazón}, J. Trujillo.] MeCADi*: un
marco orientado a objetivos para el modelado de la calidad en
almacenes de datos. \emph{XIII Jornadas de Ingeniería del Software y
Bases de Datos (JISBD 2008), pp. 229-240, October 7-10, Gijón,
Spain. ISBN: 978-84-612-5820-8.}

\item[\textbf{J-N. Mazón}, J. Lechtenbörger, J. Trujillo.] Impacto de las
multiplicidades en la resolución de problemas de sumarizabilidad
para OLAP.  \emph{XIII Jornadas de Ingeniería del Software y Bases
de Datos (JISBD 2008), pp. 421-426, October 7-10, Gijón, Spain.
ISBN: 978-84-612-5820-8.}

\item[\textbf{J-N. Mazón}, J. Trujillo.] Desarrollo de modelos
multidimensionales de almacenes de datos basado en MDA: del análisis
de requisitos al modelo lógico. \emph{IV Taller sobre Desarrollo de
Software Dirigido por Modelos, MDA y Aplicaciones (DSDM 2007),
Zaragoza, Spain. September 11, 2007.}

\item[\textbf{J-N. Mazón}, E. Ortega, J. Trujillo.] Ingeniería inversa dirigida
por modelos para el diseño de almacenes de datos. \emph{XII Jornadas
de Ingeniería del Software y Bases de Datos (JISBD 2007), pp. 63-72,
September 11-14, 2007, Zaragoza, Spain. ISBN: 978-84-9732-595-0.}

\item[M. Serrano, R. Romero, \textbf{J-N. Mazón}, J. Trujillo, M. Piattini.] Una
propuesta de un modelo conceptual de calidad de almacenes de datos.
\emph{XII Jornadas de Ingeniería del Software y Bases de Datos
(JISBD 2007), pp.297-306, September 11-14, 2007, Zaragoza, Spain.
ISBN: 978-84-9732-595-0.}

\item[S. Meliá, J. Gómez, J.L. Serrano, \textbf{J-N. Mazón}.] Un perfil UML
para la definición de un len\-gua\-je gráfico de transformaciones
basado en QVT. \emph{XI Jornadas de Ingeniería del Software y Bases
de Datos (JISBD 2006), pp. 433-442, October 3-6, 2006, Sitges,
Barcelona, Spain. ISBN 84-95999-99-4.}

\item[\textbf{J-N. Mazón}, J. Pardillo, S. Meliá, J. Trujillo.] Modelado
multidimensional de almacenes de datos con MDA. \emph{XI Jornadas de
Ingeniería del Software y Bases de Datos (JISBD 2006), pp. 77-86,
October 3-6, 2006, Sitges, Barcelona, Spain. ISBN 84-95999-99-4.}

\item[\textbf{J-N. Mazón}, J. Trujillo, M. Serrano, M. Piattini.] Diagramas de
casos de uso para el análisis de requisitos en almacenes de datos.
\emph{X Jornadas de Ingeniería del Software y Bases de Datos (JISBD
2005), pp. 289-294, September 14-16, 2005, Granada, Spain. ISBN
84-9732-434-X.}

\item[\textbf{J-N. Mazón}, J. Trujillo, M. Serrano, M. Piattini.] Especificación
de jerarquías de dimensión en un almacén de datos usando WordNet.
\emph{X Jornadas de Ingeniería del Software y Bases de Datos (JISBD
2005), pp. 294-300, September 14-16, 2005, Granada, Spain. ISBN
84-9732-434-X.}

\end{description}


\section{Research Objectives and Initial Hypotheses}
\label{c2s1} Data warehouse (DW) systems provide a multidimensional
(MD) view of huge amounts of historical data from operational
sources, thus supplying useful information which allows decision
makers to improve business processes in organizations. The MD
paradigm structures information into facts and dimensions. A fact
contains the interesting measures (fact attributes) of a business
process (sales, deliveries, etc.), whereas a dimension represents
the context for analyzing a fact (product, customer, time, etc.) by
means of hierarchically organized dimension attributes.

%Mostrar una figura de un modelo multidimensional o esquema estrella

MD modeling requires specialized design techniques that resemble the
traditional database design
methods~\cite{DBLP:conf/dolap/RizziALT06}. First, a conceptual
design phase is carried out, whose output is an
implementation-independent and expressive conceptual MD model for
the DW. A logical design phase then aims to obtain a
technology-dependent model from the previously defined conceptual MD
model. This logical model is the basis for the implementation of the
DW. Therefore, there are two cornerstones in MD modeling: how to
define a conceptual MD model that reflects real world scenarios and
how to derive the most suitable logical representation.

On one hand, with regard to conceptual design, current approaches
usually embrace one of the following perspectives: (i)
\emph{data-driven}~\cite{DBLP:journals/ijcis/GolfarelliMR98,DBLP:conf/edbt/CabibboT98,DBLP:conf/dmdw/HusemannLV00},
in which the conceptual MD model is based on a detailed analysis of
the data sources, while information requirements are only considered
later when the implemented MD model is queried; and (ii)
\emph{requirement-driven}~\cite{DBLP:conf/hicss/WinterS03,DBLP:conf/re/PaimC03},
in which the conceptual MD model design is based on decision makers'
information needs, thus considering the available data sources
later, when the DW is populated. Nevertheless, although data-driven
approaches simplify the process of properly populating the DW, user
needs and expectations may not be satisfied by the MD model designed
because these approaches do not provide enough mechanisms through
which to analyze and understand the decision making process
supported by the DW. Moreover, data-driven approaches do not provide
mechanisms to highlight the important parts of the data sources,
thus wasting resources by specifying unneeded information structures
in the MD model. Conversely, requirement-driven approaches involve
decision makers in the development of the MD model, but lack
mechanisms through which to formally match the data sources with
information requirements in early stages of the development, thus
making the correct population of the DW highly complex, as the
correspondence between the elements of the MD model and their
counterparts in the data sources may not be obvious. In order to
overcome these drawbacks, some
authors~\cite{DBLP:conf/dolap/RizziALT06} argue that the most
promising solution consists of formally \emph{considering both the
data sources and the requirements in a hybrid approach}.

%Figura de bottom-up y top-down

On the other hand, once a conceptual MD model has been designed, a
further important issue must be faced: obtaining a logical
representation of the conceptual MD model. It is important to note
that a semantic gap usually exists between the elements represented
in rich conceptual MD models and their logical
representation~\cite{DBLP:conf/dolap/RizziALT06}. In particular,
current decision making tools do not allow designers to implement
every kind of MD structure, and they are thus restricted to a
limited set of them in favor of
\emph{summarizability}~\cite{DBLP:journals/vldb/JensenKPT04,MalZim2008:book}.
Summarizability refers to the possibility of accurately computing
aggregate values with a coarser level of detail from values with a
finer level of detail within an MD model. The violation of this
course of action may otherwise lead to imprecise results and thus to
erroneous analysis and
decisions~\cite{DBLP:conf/ssdbm/LehnerAW98,DBLP:conf/ssdbm/LenzS97}.
In addition, summarizability is a necessary precondition for
performance optimizations based on pre-aggregation, i.e., using the
results of previously computed queries to answer new queries more
efficiently~\cite{DBLP:journals/vldb/JensenKPT04,DBLP:conf/vldb/PedersenJD99}.
Therefore, summarizability issues need to be resolved in order to
preserve all information captured by the definition of MD structures
at the conceptual level in logical representations. Interestingly,
as deriving this logical representation from the conceptual MD model
is a complex, tedious and error-prone task for the designer since it
requires a high degree of expertise, it should be \emph{automated as
far as possible} if failures in the implementation of the DW are to
be avoided.

Bearing these considerations in mind, the \textbf{initial
hypotheses} of this PhD Thesis are the improvement of the
development of the DW by highlighting the importance of two tasks:
(i) the formal reconciliation of the operational data sources and
the information needs of decision makers at the conceptual level,
and (ii) the formal specification of transformations which will
allow designers to obtain the most suitable logical representation
of the developed conceptual MD model in an automatic manner.

%While the first task implies the definition of approaches for
%requirement analysis in the DW domain, data reverse engineering for
%MD models and the own reconciliation process, the second task has
%been performed by defining a basic transformation process and later
%adding the sumarizability-aware transformations.

If the previously stated tasks are to be successfully addressed,
then it is necessary to consider a \emph{Model Driven Development}
(MDD) process. MDD supports these tasks by offering mechanisms with
which to both manage the integration of models and to define formal
transformations between them in order for them to be automatically
executed. Other works (such
as~\cite{DBLP:journals/sigmod/VelaFMP06}) have, in fact, taken
advantage of using MDD in database development . However, to the
best of our knowledge, this work is the first to tackle specific MD
modeling problems and overcome them by using MDD.

Therefore, we can conclude by stating that the \textbf{research
goal} of this PhD Thesis is the development of a hybrid approach for
MD modeling in a systematic, well structured and comprehensive
manner, which will establish a set of formal transformations with
which to automatically obtain the final implementation of the MD
model from the defined conceptual MD model without summarizability
problems.


\section{PhD Thesis in a Nutshell}
\label{c2s3}

The research goal is tackled in two phases, the first of which is
the definition of a model-driven approach for MD modeling and the
second of which is the addition of the required mechanisms to avoid
the semantic gap between conceptual and logical levels with regard
to summarizability.


\subsection{Model-driven Multidimensional Design}

The MD modeling of DWs should take into account both user
requirements and data sources at early stages of the development.
Furthermore, this design process should establish a set of formal
transformations in order to obtain the final implementation of the
MD model in an automatic manner. In this PhD Thesis, these issues
are dealt with in the following manner: a model-driven
approach\footnote{Although the focus of this research is on
describing an approach for the MD modeling of the DW, for the sake
of completeness, this approach has been included into an overall
framework that considers every other part of a DW: ETL processes,
data analysis tools, and so on (see Chapter~\ref{c3}).} is described
which (i) combines both data-driven and requirement-driven
strategies in an integrated fashion (i.e. it is a hybrid approach)
in such a way that the DW meets decision makers' needs and
simultaneously agrees with data sources, and (ii) it provides a
repository of formal transformations through which to include the
knowledge concerning how to automatically obtain a suitable logical
representation from a conceptual MD model, thus ameliorating the
tedious and prone to fail task of designers who can save time and
effort in obtaining the implementation of the DW.

Several parts of the overall MD modeling approach (see
Fig.~\ref{c2:fig:approach}) have been separately defined during the
development of the PhD
Thesis~\cite{DBLP:conf/dawak/MazonPT06,DBLP:conf/er/MazonPT07,DBLP:conf/er/MazonT07,journals/dss/Mazon2008,DBLP:conf/er/MazonTL06,journals/dke/Mazon2007},
the work described in~\cite{DBLP:journals/dke/Lujan-MoraTS06} being
a starting point for this research. The novelty of this approach is
that it considers a hybrid viewpoint for MD modeling in a
systematic, well structured and comprehensive manner, whilst a set
of formal transformations are simultaneously established in order to
support designer in automatically obtaining the final implementation
of the MD model. It is important to note that our approach is based
on the \emph{Model Driven Architecture} (MDA)~\cite{OMG/MDA}
proposed by the \emph{Object Management Group} (OMG) as a standard
to carry out the MDD. As is shown in Fig.~\ref{c2:fig:approach}, a
conceptual MD model of the DW (\emph{Platform Independent Model},
PIM) is developed from an information requirements model
(\emph{Computation Independent Model}, CIM) obtained from decision
makers~\cite{DBLP:conf/er/MazonPT07}. This initial PIM must then be
reconciled with the data
sources~\cite{journals/dke/Mazon2007,DBLP:conf/er/MazonT07}, thus
obtaining a hybrid PIM. Moreover, several logical models can be
derived from this hybrid PIM as \emph{Platform Specific Models}
(PSMs), by taking into account different deployment platforms
(relational, multidimensional, etc.). Finally, the code for the
implementation of the MD model according to each PSM should be also
obtained. It is worth noting that the presented approach is
supported by an \emph{Eclipse}-based tool which has been developed
as a proof of concept of this research.

\begin{figure}
\begin{center}
\includegraphics[width=0.9\textwidth]{img/summary/approach.png}
\end{center}
\caption{Hybrid MDA-based approach for MD modeling}
\label{c2:fig:approach}
\end{figure}


Each part of this MDA-based approach is summarized as follows. The
reader is referred to each specific chapter of this PhD Thesis for
further explanation.


\subsubsection{Multidimensional CIM}
The first step of the approach presented in this PhD Thesis is to
elicit and model the information requirements of decision makers.
This is described in greater detail in \emph{Chapter~\ref{c5}}.

An explicit requirement analysis stage is needed in order to model
decision makers' information requirements and to derive a suitable
conceptual MD model which meets their real needs, thus increasing
the success of a DW project. Decision makers who use DWs are often
unaware of how to describe information requirements in a suitable
manner, since they are concerned rather with the goals which the DW
helps to fulfil. Therefore, a requirement analysis phase for DWs
must ideally start by discovering decision makers' goals. The
information requirements can be discovered more easily from these
goals.

Goals related to the DW can be specified on three levels:
\emph{Strategic goals}, which are the main objectives of the
business process: ``increase sales'', ``increase number of
customers'', ``decrease cost'', etc.; \emph{decision goals}, which
aim to take the appropriate actions to fulfil a strategic goal, for
example ``define some kind of promotion'' or ``open new stores'';
and finally, \emph{information goals}, which are related to the
information required by a decision goal if they are to be achieved,
examples of which might be ``analyze customer purchases'' or
``examine stocks''. Once these goals have been defined,
\emph{information requirements} can be obtained directly from the
information goals. The various MD elements, such as \emph{facts} or
\emph{dimensions}, will be discovered from these information
requirements in order to specify the corresponding conceptual MD
model of the DW.

The \emph{i*} modeling framework~\cite{DBLP:conf/re/Yu97} has been
extended for the DW domain in order to model this hierarchy of goals
and their corresponding information requirements. This framework
provides mechanisms with which to represent the various actors,
their dependencies, and with which to structure the business goals
that the organization wishes to achieve. In order to model goals and
information requirements in an MD CIM, the UML (\emph{Unified
Modeling Language})~\cite{OMG/UML} has been used to
define~\cite{DBLP:conf/er/MazonPT07} (i) a UML profile for the
\emph{i*} modeling framework, and (ii) a UML profile which adapts
\emph{i*} to the DW domain. Both profiles are described in
Sec.~\ref{c2:implementation}.

\subsubsection{Initial Multidimensional PIM} Once goals and
information requirements have been specified in a CIM, a conceptual
MD model that supports them must be derived in an initial PIM
independently of any database technology. This part of the approach
is described in \emph{Chapter~\ref{c5}} and
in~\cite{DBLP:conf/er/MazonPT07}.

Several QVT (\emph{Query/View/Transformation})~\cite{OMG/QVT}
transformation rules are applied to obtain the initial PIM, thus
assuring traceability between goals and information requirements in
the CIM and MD elements in the PIM. The definition of the PIM is
based on the UML profile for conceptual MD modeling presented
in~\cite{DBLP:journals/dke/Lujan-MoraTS06} (see
Sect.~\ref{c2:implementation}).

\subsubsection{Hybrid Multidimensional PIM}
As is previously described, the initial PIM is directly derived from
the CIM, thus ensuring that the DW will be useful in fulfilling
decision makers' goals. However, this initial PIM is defined without
taking the operational data sources into account, and it may not
agree with these sources because decision makers may have a limited
view of them. The initial PIM might not, therefore, be
\emph{faithful} (it may not be properly populated from data sources)
or \emph{complete} (it may not capture the analysis potential
provided by the data sources). Hence, if these flaws are to be
avoided, then this initial PIM must be checked against the available
data sources in a reconciliation process. This part of the approach
is described in \emph{Chapters~\ref{c5} and~\ref{c6}}.

Interestingly, several multidimensional normal forms have been
developed~\cite{DBLP:journals/is/LechtenborgerV03} in order to
provide rigorous reasoning with regard to various desirable
properties of a conceptual MD model derived from operational data
sources (among others, faithfulness and completeness). Hence, we
have developed a set of QVT relations based on these
multidimensional normal forms~\cite{journals/dke/Mazon2007} to
ensure that an initial PIM is faithful and complete with regard to
the source databases, thus obtaining a hybrid PIM.

The approach through which a hybrid PIM is obtained consists of two
main phases. The first is based on considering the design of the MD
model as a software modernization task~\cite{DBLP:conf/er/MazonT07}.
The aim of this task is to link MD concepts to elements of the data
sources, thus facilitating the subsequent
phase~\cite{DBLP:conf/dolap/SongKD07}. This first phase starts by
using data reverse engineering mechanisms to obtain a logical
representation of data sources. Our motivation is that operational
data sources are, in reality, legacy systems, and therefore the
documentation is not generally available, it cannot be obtained, or
it is too complex to be easily understandable through a manual
analysis~\cite{DBLP:journals/is/Alhajj03}. This first phase
concludes with the application of a set of QVT rules with which to
identify MD concepts (fact, dimension, measure and so on) in the
logical representation of data sources in order to obtain a marked
logical model.

The second phase consists of reconciling the initial PIM with the
marked logical model of data sources by using a set of QVT relations
based on multidimensional normal
forms~\cite{DBLP:conf/er/MazonTL06,journals/dke/Mazon2007}, thus
obtaining a hybrid PIM. These relations focus on detecting the
functional dependencies (FDs) implied by the initial PIM and by the
source databases. \emph{Faithfulness} is checked by ensuring that
the FDs implied by the initial PIM are a subset of those observed in
the source databases (otherwise, some source data cannot be
represented under the MD model), while \emph{completeness} is
enforced by ensuring that FDs among dimension levels contained in
the source databases are represented in the PIM and that FDs among
sets of measures contained in the source databases are represented
via derivation formulas in the PIM (otherwise analysis potential in
the MD model is lost). Furthermore, multidimensional normal forms
ensure that each measure is assigned to a fact at the ``right''
level of detail (without redundancies). The set of developed QVT
relations based on the multidimensional normal forms enforces these
properties by removing, adding or modifying elements in the initial
PIM, thus obtaining the hybrid PIM.

The great benefit of this hybrid PIM lies in the fact that it
faithfully represents the data sources and completely captures their
analysis potential whilst decision makers' information requirements
are simultaneously fulfilled.

\subsubsection{Multidimensional PSM} A PSM represents the model of
the same system specified by the PIM, but it also captures how that
system makes use of one specific platform or technology. In MD
modeling, platform-specific means that the PSM is specially designed
for a kind of database technology: \emph{relational technology}
(relational database to store multidimensional data) as is described
in \emph{Chapter~\ref{c3}}, \emph{multidimensional technology} (it
directly structures the data into multidimensional structures) as is
shown in \emph{Chapter~\ref{c4}} or any other technology.

In the approach proposed in this PhD Thesis, a set of QVT
transformations have been developed to obtain each PSM. Each PSM
conforms to a metamodel of CWM (\emph{Common Warehouse
Metamodel})~\cite{OMG/CWM}. Basically, CWM is a metamodel definition
through which to interchange DW specifications between different
platforms and tools. CWM provides a set of metamodels that are
sufficiently comprehensive to permit the modeling of an entire DW
including data sources, ETL processes, MD modeling, relational
implementation of a DW, and so on. These metamodels are intended to
be generic, external representations of metadata to ensure their
interchange among different platforms and tools. Interestingly, the
use of CWM has been highlighted as a desirable requirement for
managing metadata in business intelligence
scenarios~\cite{DBLP:conf/dawak/Pedersen04}.

Finally, a set of \emph{Models to Text} (Mof2Text)
transformations~\cite{OMG/MOF2TEXT} has been developed to obtain the
corresponding code for each PSM. For instance, a relational PSM
would derive SQL code. Moreover, since the CWM metamodels are close
to their respective technologies, deriving the corresponding code is
a straightforward task which is dealt with solely in
Sect.~\ref{c2:implementation} of this PhD Thesis.

\subsubsection{Implementation}
\label{c2:implementation}

After testing several platforms, such as
\emph{Rational}~\cite{RATIONAL} or \emph{Borland Together
Architecture}~\cite{BORLAND}, the presented approach has been
implemented by using the \emph{Eclipse development
platform}~\cite{ECLIPSE}. \emph{Eclipse} is a framework which can be
extended by means of plugins in order to add more features and new
functionalities. A plugin that supports every part of the approach
presented in this PhD Thesis has been developed~\cite{RE08}. This
new plugin has the following modules:

\begin{description}
\item[\textbf{CIM module.}] This module implements the UML profile
for using \emph{i*} in the DW domain. A CIM can be specified by
using this module. The \emph{i*} modeling framework provides
mechanisms with which to represent the various DW actors, their
dependencies, and with which to structure the business goals that
the organization wishes to achieve. The main elements of \emph{i*}
are described in Tab.~\ref{c2:tab:istar}. The \emph{i*} profile for
DWs has been developed on the basis of these elements by including
new stereotypes (see Fig.~\ref{c2:fig:profile-i}). The corresponding
icons are shown in Fig.~\ref{c2:istarpalette}.

\begin{table}
\caption{Main elements for modeling in \emph{i*}}
\label{c2:tab:istar}
\begin{tabular}{p{0.3\textwidth}p{0.7\textwidth}}
\hline\noalign{\smallskip}
Stereotype & Description  \\
\noalign{\smallskip}\hline\noalign{\smallskip}
\textsc{Actor}  & An entity that carries out actions in order to perform goals. It is related to various intentional elements (goal, task or resource).\\
\textsc{Goal} & A condition or state that the stakeholder would like to achieve. In the DW context, strategic, decision and information goals can be represented by its use.\\
\textsc{Task} & This represents a particular way of doing something. In the DW context a task is related to the manner in which the data is required (information requirement). \\
\textsc{Resource}  & This is an entity which must be available if it is to be used. In the DW context a resource is related to a piece of data, e.g. a measure.\\
\textsc{Means-ends}  & This association describes how goals are achieved by representing which are the necessary elements for achieving the goal. \\
\textsc{Decomposition}  & This association defines what other elements need to be available in order to perform a task. \\
\noalign{\smallskip}\hline\noalign{\smallskip}
\end{tabular}
\end{table}

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{img/summary/profile-i}
\end{center}
\caption{UML profiles for \emph{i*} modeling in DWs}
\label{c2:fig:profile-i}
\end{figure}



Decision makers' goals are defined by using the \emph{Strategic},
\emph{Decision}, and \emph{Information} stereotypes. Information
requirements (\emph{Requirement}) are derived from information goals
and are represented as stereotyped tasks. Furthermore, the
requirement analysis for DWs necessitates the addition of certain MD
concepts (in the sense of~\cite{DBLP:conf/dolap/GiorginiRG05}).
Therefore, the following concepts are added to the CIM as
stereotyped resources: business processes related to the goals of
decision makers (\emph{BusinessProcess} stereotype), relevant
measures related to decision makers' information requirements
(\emph{Measure}), and the contexts needed to analyze these measures
(\emph{Context}). Foreseen relations between the contexts of
analysis are additionally modeled. For instance, the city and the
country contexts should be related since cities can be aggregated in
countries. The (shared) aggregation relationship of UML has been
used to model these relationships.

\item[\textbf{PIM module.}] This module implements the UML profile
for MD modeling which allows us to define a conceptual MD model in a
PIM.

The definition of the PIM is based on the UML profile for conceptual
MD modeling presented in~\cite{DBLP:journals/dke/Lujan-MoraTS06}.
This profile contains the stereotypes (see
Fig.~\ref{c2:fig:profile-md}) which are necessary to represent MD
properties at the conceptual level by means of a UML class diagram
in an elegant manner. The main elements of this profile are
described in Tab.~\ref{c2:tab:md} (the corresponding icons are shown
in Fig.~\ref{c2:mdpalette}). This profile is formally defined and
uses the \emph{Object Constraint Language} (OCL)~\cite{OMG/OCL} to
express well-formed rules of the newly defined elements, thereby
avoiding its arbitrary use.

\begin{figure}
\begin{center}
\includegraphics[width=0.7\textwidth]{img/summary/profile-md}
\end{center}
\caption{UML profile for MD modeling of DWs}
\label{c2:fig:profile-md}
\end{figure}

\begin{table}
\caption{Main stereotypes of our UML profile for MD modeling of DWs}
\label{c2:tab:md}       % Give a unique label
%
% Follow this input for your own table layout
%
\begin{tabular}{p{0.25\textwidth}p{0.2\textwidth}p{0.55\textwidth}}
\hline\noalign{\smallskip}
Stereotype & Extends & Description \\
\noalign{\smallskip}\hline\noalign{\smallskip}
\textsc{Fact} & Class  & Classes of this stereotype represent facts in an MD model, consisting of measures (the values being analyzed).\\
\textsc{Dimension} & Class & These classes represent dimensions in an MD model, consisting of hierarchy levels. \\
\textsc{Base} & Class & Classes of this stereotype represent dimension hierarchy levels consisting of dimension attributes. \\
\textsc{FactAttribute} & Property & These properties represent attributes of a fact (i.e. measures) in an MD model. They can represent a derived measure, thus including a derivation rule.\\
\textsc{DimensionAttribute} & Property & These represent descriptive information of a dimension hierarchy level in an MD model. \\
\textsc{Descriptor} & Property & These represent descriptor attributes of a dimension hierarchy level in an MD model.\\
\textsc{Rolls-UpTo} & Association & These represent relationships between two \emph{Base} classes. Role \emph{r} represents the direction in which the hierarchy rolls-up, and role \emph{d} represents the direction in which the hierarchy drills-down. \\
\noalign{\smallskip}\hline\noalign{\smallskip}
\end{tabular}
\end{table}


\item[\textbf{PSM module.}] This module implements the CWM Resource
layer in order to define logical models for the DW. This layer
consists of a set of standard metamodels through which to represent
the structure of data according to different technologies. For
example, the \emph{relational} metamodel (see Fig.~\ref{c2:fig:cwm})
contains classes and associations which represent every aspect of
relational databases. This metamodel facilitates the representation
of tables, columns, primary keys, foreign keys and so on.

\begin{figure}
\begin{center}
\includegraphics[width=0.7\textwidth]{img/summary/cwm}
\end{center}
\caption{Excerpt of the CWM relational metamodel} \label{c2:fig:cwm}
\end{figure}



\item[\textbf{QVT module.}] Several transformation engines such as
\emph{mediniQVT}~\cite{MEDINI} or \emph{smartQVT}~\cite{SMARTQVT}
have been tested. However, the \emph{ATLAS Transformation Language}
(ATL) engine~\cite{ATL} was eventually chosen. This module takes
advantage of ATL to implement all the QVT transformations defined as
part of the model-driven approach and to execute them.

\item[\textbf{Code module.}] This module uses a text transformation
engine called \emph{MOFScript}~\cite{MOFSCRIPT} to implement the set
of Mof2Text transformations in order to obtain the code from the
PSMs.

\end{description}


Several graphical and textual editors have been implemented in each
module to create a tool with which to design the different models
and apply the QVT and Mof2Text transformations.
Fig.~\ref{c2:fig:screenshot} shows an overview of the
tool\footnote{For the sake of the understandability of the
\emph{Eclipse} framework, only detailed parts of the screenshots are
shown from now on.}. The different models (CIM, PIM and PSM) and the
code are stored in several folders when a project is created (the
project explorer is shown in Fig.~\ref{c2:fig:project}). Various
palettes have also been created in order to draw the different
elements of the profiles (see Fig.~\ref{c2:fig:parts}). A palette
for the UML profile of \emph{i*} in the DW domain is shown in
Fig.~\ref{c2:istarpalette}, while a palette for the UML profile for
MD modeling is shown in Fig.~\ref{c2:mdpalette}. Furthermore, each
transformation could be launched by using the corresponding option
of the \emph{``Transform''} menu (Fig.~\ref{c2:fig:menutransform}).

%Describir: modelo vs diagrama, uso de UML2Tools...


\begin{figure}[h!t]
\begin{center}
\includegraphics[width=\textwidth]{img/summary/screenshot.png}
\end{center}
\caption{Screenshot of the \emph{Eclipse}-based tool}
\label{c2:fig:screenshot}
\end{figure}

\begin{figure}[h!t]
\subfigure[Explorer]{
\includegraphics[width=0.2\textwidth]{img/summary/project.png}
\label{c2:fig:project}} \qquad \qquad \subfigure[\emph{i*}palette]{
\includegraphics[width=0.2\textwidth]{img/summary/istarpalette.png}
\label{c2:istarpalette}} \qquad \qquad \subfigure[MD palette]{
\includegraphics[width=0.2\textwidth]{img/summary/mdpalette.png}
\label{c2:mdpalette}}  \caption{Different parts of the
\emph{Eclipse} tool} \label{c2:fig:parts}
\end{figure}

\begin{figure}[h!t]
\begin{center}
\includegraphics[width=0.9\textwidth]{img/summary/menuTransform.png}
\end{center}
\caption{Menu for launching transformations}
\label{c2:fig:menutransform}
\end{figure}


An example of how to use our tool is now illustrated through a case
study based on the strategic educational plan of the University of
Alicante
(\url{http://www.ua.es/es/presentacion/pe/psec/formacion/index.html}).
This plan determines goals and actions which must be undertaken in
order to provide a high-quality education program. This case study
specifically focuses on developing a DW that will support decision
making in the \emph{``assessment''} process of the University of
Alicante. This process is related to one main actor, the
\emph{``education manager''}, via the strategic goal
\textit{``provide a good education program''}. Three different
decision goals are derived from this strategic goal: \textit{``adapt
education program to demand''}, \textit{``achieve international
recognition''}, and \textit{``attain renowned program''}. The
following information goals have been obtained from each of these
decision goals : \textit{``evaluate environment demand''},
\textit{``analyze international impact''}, and \textit{``study
student performance''}. The derived information requirements are
defined as tasks as follows: \textit{``percentage of students per
city and province''}, \textit{``percentage of foreign students''},
\textit{``average of examination passed per subject, degree and
department''}. Furthermore, the necessary measures and contexts of
analysis are associated with the information requirements as
resources. The sole measure is \textit{``examination session''}, and
the elements that represent the context of analysis are
\textit{``student''}, \textit{``city''}, \textit{``province''},
\textit{``country''}, \textit{``subject''}, \textit{``degree''}, and
\textit{``department''}. Several of these contexts of analysis are
related to each other in order to aggregate the \textit{``student''}
and the \textit{``subject''} data.

Each of these elements is defined in a CIM according to the UML
profile for \emph{i*} (see Fig.~\ref{c2:fig:cim}).

\begin{figure}[h!t]
\begin{center}
\includegraphics[width=\textwidth]{img/summary/cim.pdf}
\end{center}
\caption{CIM of the case study} \label{c2:fig:cim}
\end{figure}

In summary, if a CIM is to be properly defined with \emph{i*}, then
several steps must be followed: (i) discovering the actors (i.e. the
decision makers), (ii) discovering their goals (strategic, decision,
and information goals), (iii) deriving information requirements from
information goals, and (iv) obtaining the measures and context of
analysis related to the information requirements.


A QVT transformation with which to automatically obtain a PIM from
the CIM has been defined~\cite{DBLP:conf/er/MazonPT07}. This
transformation takes the previously defined CIM as an input to
create certain MD elements in a PIM (as shown in
Fig.~\ref{c2:fig:pim1}). Specifically, in Fig.~\ref{c2:pim1_fact}, a
\emph{Fact} class \emph{Assessment} is created with a
\emph{FactAttribute} property \emph{ExaminationSession}. Two
\emph{Dimension} classes, and their hierarchies of \emph{Base}
classes, are also created according to the contexts of analysis
defined in the CIM (see Fig.~\ref{c2:pim1_dim1} and
Fig.~\ref{c2:pim1_dim2}).

\begin{figure}[h!t]
\subfigure[]{
\includegraphics[width=0.3\textwidth]{img/summary/pim1_fact.pdf}
\label{c2:pim1_fact}} \subfigure[]{
\includegraphics[width=0.3\textwidth]{img/summary/pim1_dim1.pdf}
\label{c2:pim1_dim1}} \subfigure[]{
\includegraphics[width=0.3\textwidth]{img/summary/pim1_dim2.pdf}
\label{c2:pim1_dim2}} \caption{Initial PIM} \label{c2:fig:pim1}
\end{figure}


The following step is to obtain a model of the data sources and mark
its elements with MD concepts (as fact, dimension, and so on). In
this case study, an \emph{Oracle}-based implementation of the data
sources exists. The process of obtaining a relational model from the
\emph{Oracle} data dictionary has been implemented by using
\emph{Java} in the \emph{Eclipse} framework. Within this process,
the \texttt{java.sql.Connection} interface is used to connect with
the \emph{Oracle} database and execute the required SQL statements
in order to obtain metadata from the data dictionary. After
obtaining all the required metadata, the corresponding model is
derived by using \emph{Eclipse} facilities and the CWM relational
metamodel. The model is then marked with MD concepts.
Figure~\ref{c2:fig:ds} shows the model of the data sources used in
our case study.

%Figura donde se muestre las properties para ver que el modelo está marcado...

\begin{figure}[h!t]
\subfigure[]{
\includegraphics[width=0.22\textwidth]{img/summary/ds1.png}
\label{c2:ds1}} \subfigure[]{
\includegraphics[width=0.22\textwidth]{img/summary/ds2.png}
\label{c2:ds2}} \subfigure[]{
\includegraphics[width=0.22\textwidth]{img/summary/ds3.png}
\label{c2:ds3}} \subfigure[]{
\includegraphics[width=0.22\textwidth]{img/summary/ds4.png}
\label{c2:ds4}} \caption{Data source model} \label{c2:fig:ds}
\end{figure}

After attaining the data source model and the initial PIM, the
reconciliation process should be launched. This reconciliation
process has been implemented in three steps according to the
multidimensional normal forms. First, in order to assure
faithfulness, for every functional dependency (FD) in the PIM we
must check that there is a corresponding FD in the data source
model, i.e., the FDs implied by the MD model must be a subset of
those observed in the source databases.  The \emph{``Required
Annotation''} option (see Fig.~\ref{c2:fig:menutransform}) launches
a set of rules with which to match each case in which an FD arises
in the PIM in order to check whether the same FD occurs in the data
source model. If this check fails then the \emph{status} of the
involved elements are labeled as \emph{required} and are colored
\emph{red} to indicate that they appear in the initial PIM but that
they have no counterparts in the data source model (i.e., they are
required by decision makers but data sources do not supply them).
For example, in Fig.~\ref{c2:fig:pim2}, \emph{ExaminationSession},
\emph{Country} and the \emph{Rolls-upTo} association between
\emph{Degree} and \emph{Department} are in red after launching this
transformation because they have no corresponding counterparts in
the data source model.

\begin{figure}[h!t]
\subfigure[]{
\includegraphics[width=0.3\textwidth]{img/summary/pim2_fact.pdf}
\label{c2:pim2_fact}} \subfigure[]{
\includegraphics[width=0.3\textwidth]{img/summary/pim2_dim1.pdf}
\label{c2:pim2_dim1}} \subfigure[]{
\includegraphics[width=0.3\textwidth]{img/summary/pim2_dim2.pdf}
\label{c2:pim2_dim2}} \caption{PIM annotated with required elements}
\label{c2:fig:pim2}
\end{figure}

Once faithfulness has been checked, the second step is to assure
completeness. It is essential to check that:

\begin{itemize}
\item The FDs among dimension levels contained
  in the source databases are represented as \emph{Rolls-upTo} arcs in the MD
  model. Otherwise, analysis potential is lost (\emph{roll-up completeness}).
\item The FDs among sets of measures
  contained in the source databases are represented via derivation
  formulas in the MD model. Otherwise, derivation relationships are
  lost (\emph{derivation completeness}).
\item Each measure is assigned to a
  fact in such a way that the terminal dimension levels of the fact form a key
  for the measure without transitive dependencies.  Otherwise, a measure is
  recorded redundantly at the ``wrong'' level of detail (\emph{avoidance of redundancies}).
\end{itemize}

These conditions are checked by launching the \emph{``Supplied
Annotation''} transformation (see Fig.~\ref{c2:fig:menutransform})
which matches each case in which an FD arises in the data source
model in order to check whether the same FD occurs in the PIM model.
If this check fails then the \emph{status} of the elements involved
are labeled as \emph{supplied} and they are colored \emph{blue} to
indicate that they appear in the data source model but that they
have no counterparts in the initial PIM (i.e., they are supplied by
data sources but decision makers did not require them). For example,
Fig.~\ref{c2:fig:pim3_1} and Fig.~\ref{c2:fig:pim3_2} show new
elements in blue which are part of the data sources but which do not
appear in the initial PIM.
%Finally, a \emph{Dimension} class \emph{Date} is introduced, since
%it is always a mandatory requirement for decision makers in MD
%modeling~\cite{book/Kimball/DW}.

\begin{figure}[h!t]
\subfigure[]{
\includegraphics[width=0.4\textwidth]{img/summary/pim3_fact.pdf}
\label{c2:pim3_fact}} \subfigure[]{
\includegraphics[width=0.4\textwidth]{img/summary/pim3_dim1.pdf}
\label{c2:pim3_dim1}}  \caption{PIM annotated with supplied elements
(1/2)} \label{c2:fig:pim3_1}
\end{figure}


\begin{figure}[h!t]
\subfigure[]{
\includegraphics[width=0.4\textwidth]{img/summary/pim3_dim2.pdf}
\label{c2:pim3_dim2}} \subfigure[]{
\includegraphics[width=0.4\textwidth]{img/summary/pim3_dim3.pdf}
\label{c2:pim3_dim3}}  \caption{PIM annotated with supplied elements
(2/2)} \label{c2:fig:pim3_2}
\end{figure}

Until now, each element of the initial PIM has been labeled with one
status (\emph{required} or \emph{supplied}) or it has not been
labeled (status is \emph{none}). It is the designer's task to check
the resulting model and change the status of each element to
\emph{none} (see Fig.~\ref{c2:fig:setstatusnone}) if (i) a
\emph{required} element could be provided by other external data
sources or (ii) a \emph{supplied} element might be useful for the
decision maker. Obviously, in the following step, only the elements
whose status is \emph{none} are taken into account in obtaining the
hybrid PIM (see Fig.~\ref{c2:fig:pim4_1} and
Fig.~\ref{c2:fig:pim4_2}).

\begin{figure}[h!t]
\begin{center}
\includegraphics[width=0.8\textwidth]{img/summary/setStatusNone.png}
\end{center}
\caption{Setting the status to \emph{none}}
\label{c2:fig:setstatusnone}
\end{figure}

\begin{figure}[h!t]
\subfigure[]{
\includegraphics[width=0.4\textwidth]{img/summary/pim4_fact.pdf}
\label{c2:pim4_fact}} \subfigure[]{
\includegraphics[width=0.4\textwidth]{img/summary/pim4_dim1.pdf}
\label{c2:pim4_dim1}}  \caption{PIM after removing the elements
annotated as required or supplied (1/2)} \label{c2:fig:pim4_1}
\end{figure}

\begin{figure}[h!t]
\subfigure[]{
\includegraphics[width=0.4\textwidth]{img/summary/pim4_dim2.pdf}
\label{c2:pim4_dim2}} \subfigure[]{
\includegraphics[width=0.4\textwidth]{img/summary/pim4_dim3.pdf}
\label{c2:pim4_dim3}}  \caption{PIM after removing the elements
annotated as required or supplied (2/2)} \label{c2:fig:pim4_2}
\end{figure}

Once the hybrid PIM has been obtained, the following step is to
obtain a PSM according to one specific technology. In this case, the
PSM corresponds to the most common logical representation of MD
models: the relational \emph{star schema}~\cite{book/Kimball/DW}.
This schema consists of a central fact table with a composite key
which is joined to several dimension tables, each with a single
primary key. This is shown in Fig.~\ref{c2:fig:psm}.


\begin{figure}[h!t]
\subfigure[]{
\includegraphics[width=0.3\textwidth]{img/summary/psm1.png}
\label{c2:psm1}} \subfigure[]{
\includegraphics[width=0.3\textwidth]{img/summary/psm2.png}
\label{c2:psm2}} \caption{PSM as a star schema} \label{c2:fig:psm}
\end{figure}

Finally, the code with which to implement the MD model in a
commercial tool should be obtained. On one hand, the corresponding
SQL code for the star schema is obtained from the PSM
(Fig.~\ref{c2:fig:codesql}) and, on the other hand, the
corresponding code to be used for data analysis is also obtained
from the hybrid PIM (Fig.~\ref{c2:fig:codeolap}).

\begin{figure}[h!t]
\begin{center}
\includegraphics[width=0.5\textwidth]{img/summary/codesql.png}
\end{center}
\caption{Generated SQL code for a star schema}
\label{c2:fig:codesql}
\end{figure}

\begin{figure}[h!t]
\begin{center}
\includegraphics[width=0.8\textwidth]{img/summary/codeolap.png}
\end{center}
\caption{Generated data analysis code} \label{c2:fig:codeolap}
\end{figure}

\clearpage

\subsection{Solving Summarizability Problems}
A conceptual MD model (i.e. a PIM in the previously-presented MDA
approach) provides a high level of abstraction in the accurate and
expressive description of real-world situations. We have shown how,
once this model has been designed, the corresponding logical
representation is obtained as the basis of the implementation of the
DW according to one specific technology.

However, even though a good conceptual MD model is designed beneath
a DW, there is a semantic gap between this model and its logical
representation. This gap particularly complicates a suitable
treatment of \emph{summarizability} issues, which may in turn lead
to erroneous results from data analysis tools. Research addressing
this topic has produced only partial solutions, and individual
terminology used by different parties hinders further progress.
Consequently, the MDA approach for the MD design of DWs described in
this PhD Thesis has been improved by including several
summarizability-aware transformations within the PIM-PSM
transformation. This part of the PhD Thesis is described in-depth in
Appendices~\ref{a1},~\ref{a2} and~\ref{a3}.

In order to motivate this part of the research, a survey was carried
out (see Appendix~\ref{a1}). This survey has introduced a unifying
vocabulary and sheds light on (i) the weak and strong points of
current approaches for modeling complex MD structures that reflect
real-world situations in a conceptual MD model and (ii) existing
mechanisms which can be used to avoid summarizability problems when
conceptual MD models are being implemented. The conducted survey
suggests that summarizability should be ensured by using a
comprehensive DW design process and that this process should be
supported by a tool in order to support:
\begin{enumerate}
\item The adequate representation of interactions between dimensions and
  facts~\cite{DBLP:conf/dmdw/SongRME01}.
\item The adequate representation of relationships between levels of
  aggregation within a dimension
  hierarchy~\cite{DBLP:conf/vldb/JagadishLS99}.
\end{enumerate}


The notion of \emph{summarizability} was introduced by Rafanelli and
Shoshani~\cite{DBLP:conf/ssdbm/RafanelliS90} in the context of
statistical databases, in which it refers to the correct computation
of aggregate values with a coarser level of detail from aggregate
values with a finer level of detail. Although this work focuses
solely upon the relationships between two levels of a dimension
hierarchy, the relationships between facts and dimensions can also
cause summarizability problems in MD
modeling~\cite{DBLP:conf/ssdbm/LehnerAW98}. Every MD model to be
implemented must ensure summarizability in these two kind of complex
MD structures since, otherwise, its violation may lead to incorrect
results, and therefore to erroneous analysis
decisions~\cite{DBLP:conf/ssdbm/LenzS97}.

In view of these complications, the traditional manner in which to
proceed is to implement an MD model without those MD structures
which may cause summarizability problems. Of course, this simplistic
approach hampers designers as they cannot use the full
expressiveness of rich conceptual models. Consequently, they waste a
lot of effort in implementing the MD model via less expressive MD
constructs, and have to be more careful to obtain a faithful
representation of real-world scenarios.

In contrast, according to some
authors~\cite{DBLP:conf/dmdw/HusemannLV00,DBLP:conf/dolap/RizziALT06,DBLP:conf/er/SapiaBHD98,DBLP:journals/computer/TrujilloPGS01,DBLP:conf/dolap/TryfonaBC99}
MD modeling aims to represent every MD element in an implementation
independent conceptual model, thus reflecting real-world situations
as accurately as possible. Once a conceptual MD model has been
designed, the corresponding logical representation must be obtained
as the basis of the implementation of the MD model according to one
specific technology. However, the semantic gap between the elements
represented in rich conceptual MD models and their logical
representation must be bridged to preserve all the information
captured by the definition of complex MD structures at the
conceptual level in logical representations, while summarizability
issues are simultaneously
resolved~\cite{DBLP:journals/vldb/JensenKPT04,MalZim2008:book}.
Moreover, as deriving a logical representation from the conceptual
MD model is a tedious and error-prone task for the designer, it
should be automated as far as possible.

Until now, few approaches have considered the issues mentioned above
in combination, in order to first model all kinds of real-world
hierarchies and fact-dimension relationships at the conceptual level
and to then automatically derive a logical representation that
preserves the information defined at the conceptual level, avoiding
summarizability
problems~\cite{DBLP:journals/dke/MalinowskiZ06,DBLP:journals/is/PedersenJD01,DBLP:conf/dawak/MansmannS06}.
Furthermore, the approaches proposed so far suffer from the
following drawbacks: (i) informal mechanisms are sketched to avoid
summarizability problems, which hinders automatic solutions or (ii)
instance transformations (rather than schema transformations) are
required to avoid summarizability problems, which require complex
preprocessing tasks that may result in performance problems and
produce ``artificial'' data instances that are difficult to
interpret during analysis.

In order to overcome these problems, the MDA approach previously
presented has been extended with a \emph{normalization process}. In
essence, as is shown in Fig.~\ref{c2:fig:normalization}, once a PIM
(which permits the representation of complex MD structures) has been
designed, we obtain from this PIM---via the automatic execution of
formal QVT~\cite{OMG/QVT} transformation rules---a normalized PIM
which captures the information represented in the conceptual MD
model but is constrained to those elements and relationships that do
not violate summarizability. It is then easy to obtain a PSM from
this normalized PIM.

\begin{figure}
\begin{center}
\includegraphics[width=0.8\textwidth]{img/summary/normalization.png}
\end{center}
\caption{Normalization process to avoid summarizability problems}
\label{c2:fig:normalization}
\end{figure}

This normalization process has been implemented together with the
\emph{Eclipse}-based tool previously commented on. A plugin that
supports the normalization process has been developed, which
implements all of the QVT transformations described. This plugin
takes advantage of the ATL~\cite{ATL} engine to implement all QVT
relations and to execute them in order to carry out the
normalization process in an automatic manner. A screenshot is shown
in Fig.~\ref{c2:fig:normalizationATL}.

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{img/summary/normalizationATL.png}
\end{center}
\caption{ATL-based implementation of the normalization process in
\emph{Eclipse}} \label{c2:fig:normalizationATL}
\end{figure}


\section{Conclusions}
A DW is an integrated collection of historical data which supports
management's decisions. According to this definition, in the
development of an MD model for the DW, it is not only important to
take into account the information needs of decision makers
(requirement-driven approaches), but also the existing data sources
that will populate the DW (data-driven approaches). Therefore,
formal mechanisms are needed to integrate these two points of view
in a hybrid approach. Furthermore, the MD modeling of the DW
resembles the traditional database design
methods~\cite{DBLP:conf/dolap/RizziALT06} since it must be
structured into a variety of steps during which a conceptual design
phase is carried out, whose results are transformed into a logical
data model as the basis for schema implementation. This manner of
proceeding necessitates the automation of these transformations.

This PhD Thesis presents a model-driven approach for dealing with
these issues in order to obtain a major benefit: the systematic,
well structured and comprehensive development of a hybrid MD model
at the conceptual level and the automatic derivation of its logical
representation. This approach therefore allows designers to decrease
the inherent complexity of DW development, thus saving time and
effort. Later, a normalization process has been added to this
model-driven approach in order to ensure summarizability in complex
MD structures such as dimension hierarchies and fact-dimension
relationships. An \emph{Eclipse}-based tool has also been developed
to support each part of this approach.

Finally, to the best of our knowledge this PhD Thesis is the first
work to propose a comprehensive hybrid process in DW development by
taking into account information requirements and data sources, along
with bridging the semantic gap caused by summarizability problems.

%\textbf{Not only an approach that deals with the MD modeling of DWs
%has been defined but also a general framework to align the
%development of every part of a DW with MDA (see Chapter~\ref{c3}),
%thus paving the way for future research objectives as the modeling
%of ETL process or data analysis tools...}


\bibliographystyle{abbrv}
\bibliography{tesis}


%
